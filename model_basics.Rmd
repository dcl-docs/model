```{r include=FALSE, cache=FALSE}
set.seed(858)

options(
  digits = 3,
  dplyr.print_max = 6,
  dplyr.print_min = 6
)

knitr::opts_chunk$set(
  echo = FALSE
  # cache = TRUE,
  # collapse = TRUE,
  # comment = "#>",
  # fig.align = 'center',
  # fig.asp = 0.618,  # 1 / phi
  # fig.show = "hold"
)

image_dpi <- 125


```

# Model basics

```{r message=FALSE, warning=FALSE}
# Libraries
library(tidyverse)
library(modelr)
library(tidymodels)

# Parameters
file_anscombe <- here::here("data/anscombe/anscombe_1.rds")
file_anscombe_outlier <- here::here("data/anscombe/anscombe_1_outlier.rds")

#===============================================================================

df <- read_rds(file_anscombe)
df_outlier <- read_rds(file_anscombe_outlier)

plot_format <-
  list(
    scale_x_continuous(limits = c(0, 20)),
    scale_y_continuous(limits = c(0, 15)),
    coord_fixed(),
    labs(title = "")
  )

label_model_line <- function(error_metric, a_0, a_1) {
  str_glue("{error_metric}\na_0 = {round(a_0, 2)}\na_1 = {round(a_1, 2)}")
}
```

## What is a model?

The world is complicated and messy, and there are endless details to even simple phenomena. To understand and navigate the world, we construct and use models. 

For example, think about traffic. You probably have a simple mental model that says traffic will be worse at rush hour than at two in the morning. You can use this model to describe how traffic varies throughout the day, but you can also use it to predict the level of traffic at a given hour. 

Your mental model of traffic, like any model, is an approximation. It tries to capture relevant information while ignoring noise and less important details. Your traffic mental model will never fully explain traffic, and so you'll never be a perfect predictor of how many cars will be on the road at any given time. However, if it's a good model, it will be useful.

The type of models we'll discuss in this book are similar to your mental model of traffic: they are approximations; you can use them to both describe and predict the world; and, while they will never be completely accurate, they can be useful.

## Function families

The type of mathematical model we'll talk about in this book are functions. Your job as a modeler is to find the function that best approximates your data. 

Functions map from one or more variables (e.g., time) to another (e.g., amount of traffic). Because functions have a form that you can write down, you can use them to describe the relationship between variables, but you can also plug values into your function to make predictions.

There are an infinite number of functions, so how do you know where to look? The first step is to explore your data, understand its functional form, and decide on a _function family_. Function families are sets of functions with similar forms. One of the most common function families in modeling is the family of linear functions. Linear functions of one variable take the following form: 

`y = a_0 + a_1 * x`

`x` is your input variable, the variable that you supply to the function in hopes of approximating some other variable. In our traffic example, `x` is the time of day.

`a_0` and `a_1` are the _parameters_. These two numbers define the line. The only difference between functions in the family of linear functions are their values of `a_0` and `a_1`.

To visualize this, here's a plot of many different lines, each of which has a different combination of `a_0` and `a_1`.

```{r}
tribble(
    ~a_1, ~a_0, 
    1,    3,   
    5,    -50,  
    -.1,  15,  
    -.7,  12,  
    0.1,  4,    
  ) %>% 
  ggplot(aes(x, y)) + 
  geom_abline(aes(slope = a_1, intercept = a_0)) +
  plot_format
```

`a_0` defines the y-intercept, the y-value your function will produce when `x` is 0. `a_1` is the slope, which tells you how much `y` increases for every one unit increase in `x`. Because linear functions are defined by these two parameters, your next task as a modeler is to figure out which values of `a_0` and `a_1` best approximate your data. In the next section, we'll discuss finding these two parameters.

## Fitting a model

[Anscombe's quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet) is a set of four small data sets. In this section, we'll use a slightly modified version of the first data set in the quartet. 

```{r}
df %>% 
  knitr::kable()
```

### Decide on a function family

Recall that we said the first step to fitting a model involves understanding the functional form of your data. Let's visualize the relationship between `x` and `y`.

```{r}
df %>% 
  ggplot(aes(x, y)) +
  geom_point() +
  plot_format
```

The relationship between `x` and `y` looks linear, so a function in the linear family will likely make a good approximation. 

### Decide on an error metric

Now, we need a way of determining which linear function best approximates the relationship between `x` and `y`. There are many different functions we could use.

```{r}
ab_lines <-
  tribble(
    ~intercept, ~slope,
    -1.5,       1,
    3,          0.5,
    0.75,       0.75,
    3.37,       0.52,
    2.27,       0.51
  ) %>% 
  pmap(~ geom_abline(intercept = ..1, slope = ..2, color = "blue"))
  
df %>% 
  ggplot(aes(x, y)) +
  geom_point() +
  ab_lines +
  plot_format
```

How do we decide which one is best? Let's just pick one of the lines and take a closer look.

```{r}
model_guess <- list(a_0 = -1.5, a_1 = 1)

df %>% 
  ggplot(aes(x, y)) +
  geom_point() +
  geom_abline(
    slope = model_guess$a_1, 
    intercept = model_guess$a_0, 
    color = "blue"
  ) +
  annotate(
    geom = "label",
    x = 17.3, 
    y = 14.6,
    label = str_glue("a_0 = {model_guess$a_0}\na_1 = {model_guess$a_1}"),
    hjust = 0
  ) +
  plot_format
```

By glancing at the plot, you can tell that this function isn't doing the best job of approximating our data. Most of the points where `x < 9` fall above our line, and most of the points where `x > 9` fall below the line.

To compare our chosen line to other possibilities, we need a way of quantifying how well the model approximates our data. A common way to assess model fit involves calculating the distances between the line and each of the data points.

```{r}
df %>%
  mutate(resid = y - (model_guess$a_0 + model_guess$a_1 * x)) %>% 
  ggplot(aes(x, y)) +
  geom_abline(
    slope = model_guess$a_1, intercept = model_guess$a_0, 
    color = "blue"
  ) +
  geom_segment(aes(xend = x, yend = y - resid), linetype = "dotted") +
  geom_point() +
  annotate(
    geom = "label",
    x = 17.3, 
    y = 14.6,
    label = str_glue("a_0 = {model_guess$a_0}\na_1 = {model_guess$a_1}"),
    hjust = 0
  ) +
  plot_format +
  labs(title = "Residuals")
```

These distances are called _residuals_ (or errors). Each residual represents the difference between the `y` value that the model predicts for a given `x` and the actual `y` associated with that `x`. The larger a residual, the worse your model approximates `y` at that value of `x`.  

We want to minimize all residuals, so we need to combine the individual distances into a single error metric. One common option is to find the _root mean-square error (RMSE)_. To calculate the RMSE, square each residual, find the mean, and then take the square root of that mean:

```{r eval=FALSE, echo=TRUE}
sqrt(mean(residuals^2))
```

```{r echo=FALSE}
rmse_guess <-
  df %>% 
  mutate(pred = model_guess$a_0 + model_guess$a_1 * x) %>% 
  yardstick::rmse(truth = y, estimate = pred) %>% 
  pull(.estimate)
```

The RMSE of our chosen model is `r round(rmse_guess, 2)`. We could calculate the RMSE of each model we originally plotted and pick the one with lowest value. However, because there are an infinite number of possible models, that method won't necessarily result in finding the model that minimizes RMSE. Instead, we'll hand off the work to an algorithm (implemented in an R function) that will return the values of `a_0` and `a_1` that minimize RMSE for our data.

### Find your parameters

To determine which `a_0` and `a_1` minimize RMSE, we'll use the function `lm()`. `lm()` needs two arguments: a function family and your data. Then, it finds the parameters of the function within your specified family that minimize RMSE for your data. In later chapters, you'll learn how to actually carry this out in R. For now, we'll just show you the results.

```{r}
model_lm <- lm(y ~ x, data = df)
a_0_model_lm <- coef(model_lm)[["(Intercept)"]]
a_1_model_lm <- coef(model_lm)[["x"]]
```

Here's the model that `lm()` came up with:

`y = `r a_0_model_lm` + `r a_1_model_lm` * x`

And here's the model plotted against our data:

```{r}
df %>% 
  ggplot(aes(x, y)) +
  geom_point() +
  geom_abline(intercept = a_0_model_lm, slope = a_1_model_lm, color = "blue") +
  annotate(
    geom = "label",
    x = 17.5, 
    y = 10.1,
    label = label_model_line("RMSE", a_0_model_lm, a_1_model_lm),
    hjust = 0
  ) +
  plot_format 
```

The RMSE of the model found with `lm()` is `r modelr::rmse(model_lm, df)`. You can also tell from the plot that this fitted model does a much better job of approximating our data than our previous attempt.

Again, `a_0` is the intercept, so we know that our model predicts that `y` will be `r a_0_model_lm` when `x = 0`. `a_1` is the slope, which means that our model predicts a `r a_1_model_lm` increase in `y` each time `x` increases by 1.   

Now, we'll talk more about error metric choice. 

## Error metric choice

One downside of models that minimize RMSE is that they're very sensitive to outliers. The following plot shows our original data plus an outlier.

```{r}
df_outlier %>%
  ggplot(aes(x, y)) +
  geom_point() +
  geom_point(
    color = "red", 
    data = df_outlier %>% filter(near(y, min(y)))
  ) +
  plot_format +
  labs(title = "Data with outlier")
```

If we keep using RMSE as our error metric, this single point changes the model significantly.

```{r}
model_lm_outlier <- lm(y ~ x, data = df_outlier)
a_0_rmse_outlier <- coef(model_lm_outlier)[["(Intercept)"]]
a_1_rmse_outlier <- coef(model_lm_outlier)[["x"]]

df_outlier %>% 
  ggplot(aes(x, y)) +
  geom_point() +
  geom_abline(
    intercept = a_0_model_lm,
    slope = a_1_model_lm,
    alpha = 0.3
  ) +
  geom_abline(
    intercept = a_0_rmse_outlier, 
    slope = a_1_rmse_outlier,
    color = "blue"
  ) +
  annotate(
    geom = "text", 
    label = "RMSE, no outlier",
    x = 16, 
    y = 11.5, 
    hjust = 0,
    angle = 26,
    color = "gray"
  ) +
  annotate(
    geom = "label",
    label = label_model_line("RMSE", a_0_rmse_outlier, a_1_rmse_outlier),
    x = 17,
    y = 4.3,
    hjust = 0
  ) +
  plot_format +
  labs(title = "Data with outlier")
```

The outlier pulls the slope down and the intercept up, and the model no longer approximates the rest of the data well. This plot demonstrates why it's important to visualize your model's predictions. If you only looked at the model's RMSE, you might think it was doing a good job of approximating your data.  

We want to approximate the linear trend present in the rest of the data, so we need a way to build a better model. There are two options:

* Use a different error metric.
* Exclude the outlier from the data.

First, we'll try a different error metric. Because RMSE squares each residual, a single large residual can disproportionately influence the model. Other error metrics, such as _mean absolute error (MAE)_, are less sensitive to outliers. Instead of squaring each residual, MAE finds their absolute values:

```{r eval=FALSE, echo=TRUE}
mean(abs(residuals))
```

We'll fit another model on the outlier data, using MAE as our error metric instead of RMSE.

```{r}
mae <- function(a, data) {
  resid <- data$y - pred(a, data)
  mean(abs(resid))
}

pred <- function(a, data) {
  a[1] + a[2] * data$x 
}

best_mae <- optim(c(0, 0), mae, data = df_outlier)
a_0_mae <- best_mae$par[1]
a_1_mae <- best_mae$par[2]


df_outlier %>% 
  ggplot(aes(x, y)) +
  geom_point() +
  geom_abline(
    intercept = coef(model_lm_outlier)[["(Intercept)"]],
    slope = coef(model_lm_outlier)[["x"]],
    color = "blue"
  ) +
  geom_abline(
    intercept = a_0_mae, 
    slope = a_1_mae,
    color = "#f7766d"
  ) +
  annotate(
    geom = "label", 
    label = label_model_line("MAE", a_0_mae, a_1_mae),
    x = 17.2, 
    y = 14.2, 
    hjust = 0
  ) +
  annotate(
    geom = "label",
    x = 17,
    y = 4.4,
    label = label_model_line("RMSE", a_0_rmse_outlier, a_1_rmse_outlier),
    hjust = 0
  ) +
  plot_format +
  labs(title = "Data with outlier")
```

The MAE model isn't as disproportionately affected by our outlier as the RMSE model. You can't adapt `lm()` to use MAE, but the R function `rlm()` is more flexible, and allows for many different error metrics.

The MAE model is similar to the model that we fit on the data without the outlier, which brings us to the second approach: remove the outlier. We'll talk more about this in the next chapter. 

## Summary

In this chapter, we went over the basic process of fitting a model. Here's the steps again:

* Explore your data to understand its functional form.
* Choose a function family that will approximate your data well.
* Choose an error metric. 
* Use an R function to find the specific function in the function family that minimizes the error metric. 



